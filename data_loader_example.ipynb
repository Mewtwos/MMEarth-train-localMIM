{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "\n",
    " \n",
    "# the custom dataset file also includes scripts for geobench. if you dont want that, simply comment out those lines. \n",
    "from custom_dataset import multimodal_dataset\n",
    "\n",
    "\n",
    "from MODALITIES import * # this contains all the input and output bands u need for pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args()\n",
    "\n",
    "# these 4 arguments need to be set manually\n",
    "args.data_path = '/data/mmearth/data_1M_128/data_1M_128.h5' # path to h5 file \n",
    "args.random_crop = True # ensure that if the dataset image size is 128 x 128, the resulting image after cropping is 112 x 112.\n",
    "args.random_crop_size = 112 # the size of the crop\n",
    "args.batch_size = 1\n",
    "\n",
    "# define the input and output bands for the dataset\n",
    "args.inp_modalities = INP_MODALITIES\n",
    "args.out_modalities = OUT_MODALITIES\n",
    "\n",
    "args.modalities = args.inp_modalities.copy()\n",
    "args.modalities.update(args.out_modalities) # args modalities is a dictionary of all the input and output bands.\n",
    "args.modalities_full = MODALITIES_FULL # this is a dictionary of all the bands in the dataset.\n",
    "\n",
    "# ensure all the below files are present in the same folder as the h5 file.\n",
    "args.data_name = args.data_path.split('.')[0].split('/')[-1]\n",
    "args.splits_path = args.data_path.split('.')[0] + '_splits.json'\n",
    "args.tile_info_path = args.data_path.split('.')[0] + '_tile_info.json'\n",
    "args.band_stats_path = args.data_path.split('.')[0] + '_band_stats.json'\n",
    "\n",
    "# quick check to see if all the files exist\n",
    "assert os.path.exists(args.data_path), \"Data file does not exist\"\n",
    "assert os.path.exists(args.splits_path), \"Split file does not exist\"\n",
    "assert os.path.exists(args.tile_info_path), \"Tile info file does not exist\"\n",
    "assert os.path.exists(args.band_stats_path), \"Band stats file does not exist\"\n",
    "\n",
    "args.band_stats = json.load(open(args.band_stats_path, 'r'))\n",
    "args.tile_info = json.load(open(args.tile_info_path, 'r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following line, creates a pytorch dataset object. \n",
    "dataset = multimodal_dataset(args, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dataset.__getitem__(0)\n",
    "\n",
    "# this returns a dictionary of all the modalities as key, and the corresponding data as value. The keys \n",
    "# are similar to the ones in the args.modalities dictionary, or the MODALITIES.py file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
